{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tiny_face_model",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8gdu17DMiEv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l322FbtxMwqm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model():\n",
        "    def __init__(self, weight_file_path):\n",
        "      \n",
        "      self.dtype = tf.float32\n",
        "      self.weight_file_path = weight_file_path\n",
        "      with open(self.weight_file_path, \"rb\") as f:\n",
        "        self.mat_blocks_dict, self.mat_params_dict = pickle.load(f)\n",
        "\n",
        "    def get_data_by_key(self, key):\n",
        "      \"\"\"Helper to access a pretrained model data through a key.\"\"\"\n",
        "      assert key in self.mat_params_dict, \"key: \" + key + \" not found.\"\n",
        "      return self.mat_params_dict[key]\n",
        "\n",
        "    def _weight_variable_on_cpu(self, name, shape):\n",
        "      \n",
        "      assert len(shape) == 4\n",
        "\n",
        "      weights = self.get_data_by_key(name + \"_filter\")  # (h, w, channel, filter)\n",
        "      assert list(weights.shape) == shape\n",
        "      initializer = tf.constant_initializer(weights, dtype=self.dtype)\n",
        "\n",
        "      with tf.device('/cpu:0'):\n",
        "        var = tf.get_variable(name + \"_w\", shape, initializer=initializer, dtype=self.dtype)\n",
        "      return var\n",
        "\n",
        "    def _bias_variable_on_cpu(self, name, shape):\n",
        "     \n",
        "      assert isinstance(shape, int)\n",
        "      bias = self.get_data_by_key(name + \"_bias\")\n",
        "      assert len(bias) == shape\n",
        "      initializer = tf.constant_initializer(bias, dtype=self.dtype)\n",
        "\n",
        "      with tf.device('/cpu:0'):\n",
        "        var = tf.get_variable(name + \"_b\", shape, initializer=initializer, dtype=self.dtype)\n",
        "      return var\n",
        "\n",
        "\n",
        "    def _bn_variable_on_cpu(self, name, shape):\n",
        "     \n",
        "      assert isinstance(shape, int)\n",
        "\n",
        "      name2 = \"bn\" + name[3:]\n",
        "      if name.startswith(\"conv\"):\n",
        "        name2 = \"bn_\" + name\n",
        "\n",
        "      scale = self.get_data_by_key(name2 + '_scale')\n",
        "      offset = self.get_data_by_key(name2 + '_offset')\n",
        "      mean = self.get_data_by_key(name2 + '_mean')\n",
        "      variance = self.get_data_by_key(name2 + '_variance')\n",
        "\n",
        "      with tf.device('/cpu:0'):\n",
        "        initializer = tf.constant_initializer(scale, dtype=self.dtype)\n",
        "        scale = tf.get_variable(name2 + \"_scale\", shape, initializer=initializer, dtype=self.dtype)\n",
        "        initializer = tf.constant_initializer(offset, dtype=self.dtype)\n",
        "        offset = tf.get_variable(name2 + \"_offset\", shape, initializer=initializer, dtype=self.dtype)\n",
        "        initializer = tf.constant_initializer(mean, dtype=self.dtype)\n",
        "        mean = tf.get_variable(name2 + \"_mean\", shape, initializer=initializer, dtype=self.dtype)\n",
        "        initializer = tf.constant_initializer(variance, dtype=self.dtype)\n",
        "        variance = tf.get_variable(name2 + \"_variance\", shape, initializer=initializer, dtype=self.dtype)\n",
        "\n",
        "      return scale, offset, mean, variance\n",
        "\n",
        "\n",
        "    def conv_block(self, bottom, name, shape, strides=[1,1,1,1], padding=\"SAME\",\n",
        "                   has_bias=False, add_relu=True, add_bn=True, eps=1.0e-5):\n",
        "     \n",
        "      assert len(shape) == 4\n",
        "\n",
        "      weight = self._weight_variable_on_cpu(name, shape)\n",
        "      conv = tf.nn.conv2d(bottom, weight, strides, padding=padding)\n",
        "      if has_bias:\n",
        "        bias = self._bias_variable_on_cpu(name, shape[3])\n",
        "\n",
        "      pre_activation = tf.nn.bias_add(conv, bias) if has_bias else conv\n",
        "\n",
        "      if add_bn:\n",
        "        # scale, offset, mean, variance = self._bn_variable_on_cpu(\"bn_\" + name, shape[-1])\n",
        "        scale, offset, mean, variance = self._bn_variable_on_cpu(name, shape[-1])\n",
        "        pre_activation = tf.nn.batch_normalization(pre_activation, mean, variance, offset, scale, variance_epsilon=eps)\n",
        "\n",
        "      relu = tf.nn.relu(pre_activation) if add_relu else pre_activation\n",
        "\n",
        "      return relu\n",
        "\n",
        "\n",
        "    def conv_trans_layer(self, bottom, name, shape, strides=[1,1,1,1], padding=\"SAME\", has_bias=False):\n",
        "      \n",
        "      assert len(shape) == 4\n",
        "\n",
        "      weight = self._weight_variable_on_cpu(name, shape)\n",
        "      nb, h, w, nc = tf.split(tf.shape(bottom), num_or_size_splits=4)\n",
        "      output_shape = tf.stack([nb, (h - 1) * strides[1] - 3 + shape[0], (w - 1) * strides[2] - 3 + shape[1], nc])[:, 0]\n",
        "      conv = tf.nn.conv2d_transpose(bottom, weight, output_shape, strides, padding=padding)\n",
        "      if has_bias:\n",
        "        bias = self._bias_variable_on_cpu(name, shape[3])\n",
        "\n",
        "      conv = tf.nn.bias_add(conv, bias) if has_bias else conv\n",
        "\n",
        "      return conv\n",
        "\n",
        "    def residual_block(self, bottom, name, in_channel, neck_channel, out_channel, trunk):\n",
        "      \n",
        "      _strides = [1, 2, 2, 1] if name.startswith(\"res3a\") or name.startswith(\"res4a\") else [1, 1, 1, 1]\n",
        "      res = self.conv_block(bottom, name + '_branch2a', shape=[1, 1, in_channel, neck_channel],\n",
        "                            strides=_strides, padding=\"VALID\", add_relu=True)\n",
        "      res = self.conv_block(res, name + '_branch2b', shape=[3, 3, neck_channel, neck_channel],\n",
        "                            padding=\"SAME\", add_relu=True)\n",
        "      res = self.conv_block(res, name + '_branch2c', shape=[1, 1, neck_channel, out_channel],\n",
        "                            padding=\"VALID\", add_relu=False)\n",
        "\n",
        "      res = trunk + res\n",
        "      res = tf.nn.relu(res)\n",
        "\n",
        "      return res\n",
        "\n",
        "    def tiny_face(self, image):\n",
        "        \n",
        "        img = tf.pad(image, [[0, 0], [3, 3], [3, 3], [0, 0]], \"CONSTANT\")\n",
        "        conv = self.conv_block(img, 'conv1', shape=[7, 7, 3, 64], strides=[1, 2, 2, 1], padding=\"VALID\", add_relu=True)\n",
        "        pool1 = tf.nn.max_pool(conv, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
        "\n",
        "        res2a_branch1 = self.conv_block(pool1, 'res2a_branch1', shape=[1, 1, 64, 256], padding=\"VALID\", add_relu=False)\n",
        "        res2a = self.residual_block(pool1, 'res2a', 64, 64, 256, res2a_branch1)\n",
        "        res2b = self.residual_block(res2a, 'res2b', 256, 64, 256, res2a)\n",
        "        res2c = self.residual_block(res2b, 'res2c', 256, 64, 256, res2b)\n",
        "\n",
        "        res3a_branch1 = self.conv_block(res2c, 'res3a_branch1', shape=[1, 1, 256, 512], strides=[1, 2, 2, 1], padding=\"VALID\", add_relu=False)\n",
        "        res3a = self.residual_block(res2c, 'res3a', 256, 128, 512, res3a_branch1)\n",
        "\n",
        "        res3b1 = self.residual_block(res3a, 'res3b1', 512, 128, 512, res3a)\n",
        "        res3b2 = self.residual_block(res3b1, 'res3b2', 512, 128, 512, res3b1)\n",
        "        res3b3 = self.residual_block(res3b2, 'res3b3', 512, 128, 512, res3b2)\n",
        "\n",
        "        res4a_branch1 = self.conv_block(res3b3, 'res4a_branch1', shape=[1, 1, 512, 1024], strides=[1, 2, 2, 1], padding=\"VALID\", add_relu=False)\n",
        "        res4a = self.residual_block(res3b3, 'res4a', 512, 256, 1024, res4a_branch1)\n",
        "\n",
        "        res4b = res4a\n",
        "        for i in range(1, 23):\n",
        "          res4b = self.residual_block(res4b, 'res4b' + str(i), 1024, 256, 1024, res4b)\n",
        "\n",
        "        score_res4 = self.conv_block(res4b, 'score_res4', shape=[1, 1, 1024, 125], padding=\"VALID\",\n",
        "                                     has_bias=True, add_relu=False, add_bn=False)\n",
        "        score4 = self.conv_trans_layer(score_res4, 'score4', shape=[4, 4, 125, 125], strides=[1, 2, 2, 1], padding=\"SAME\")\n",
        "        score_res3 = self.conv_block(res3b3, 'score_res3', shape=[1, 1, 512, 125], padding=\"VALID\",\n",
        "                                     has_bias=True, add_bn=False, add_relu=False)\n",
        "\n",
        "        bs, height, width = tf.split(tf.shape(score4), num_or_size_splits=4)[0:3]\n",
        "        _size = tf.convert_to_tensor([height[0], width[0]])\n",
        "        _offsets = tf.zeros([bs[0], 2])\n",
        "        score_res3c = tf.image.extract_glimpse(score_res3, _size, _offsets, centered=True, normalized=False)\n",
        "\n",
        "        score_final = score4 + score_res3c\n",
        "        return score_final\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0wOO7lPNIWT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}