{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tiny_face_eval",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8gdu17DMiEv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "5cd60813-0207-4d9d-9d74-a617eefec523"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import tensorflow as tf\n",
        "import tiny_face_model\n",
        "import util\n",
        "from argparse import ArgumentParser\n",
        "import cv2\n",
        "import scipy.io\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import pickle\n",
        "\n",
        "import pylab as pl\n",
        "import time\n",
        "import os\n",
        "import sys\n",
        "from scipy.special import expit\n",
        "import glob\n",
        "\n",
        "MAX_INPUT_DIM = 5000.0\n",
        "\n",
        "def overlay_bounding_boxes(raw_img, refined_bboxes, lw):\n",
        " \n",
        "\n",
        "  # Overlay bounding boxes on an image with the color based on the confidence.\n",
        "  count=0\n",
        "  for r in refined_bboxes:\n",
        "    _score = expit(r[4])\n",
        "    cm_idx = int(np.ceil(_score * 255))\n",
        "    rect_color = [int(np.ceil(x * 255)) for x in util.cm_data[cm_idx]]  # parula\n",
        "    _lw = lw\n",
        "    if lw == 0:  # line width of each bounding box is adaptively determined.\n",
        "      bw, bh = r[2] - r[0] + 1, r[3] - r[0] + 1\n",
        "      _lw = 1 if min(bw, bh) <= 20 else max(2, min(3, min(bh / 20, bw / 20)))\n",
        "      _lw = int(np.ceil(_lw * _score))\n",
        "\n",
        "    _r = [int(x) for x in r[:4]]\n",
        "    cv2.rectangle(raw_img, (_r[0], _r[1]), (_r[2], _r[3]), rect_color, _lw)\n",
        "    count+=1\n",
        "  print(\"--------------NUMBER OF TINY FACES IN THE IMAGE--------------------: \",count)\n",
        "    \n",
        "def evaluate(weight_file_path, data_dir, output_dir, prob_thresh=0.5, nms_thresh=0.1, lw=3, display=False):\n",
        "\n",
        "\n",
        "  # placeholder of input images. Currently batch size of one is supported.\n",
        "  x = tf.placeholder(tf.float32, [1, None, None, 3]) # n, h, w, c\n",
        "\n",
        "  # Create the tiny face model which weights are loaded from a pretrained model.\n",
        "  model = tiny_face_model.Model(weight_file_path)\n",
        "  score_final = model.tiny_face(x)\n",
        "\n",
        "  # Find image files in data_dir.\n",
        "  filenames = []\n",
        "  for ext in ('*.png', '*.gif', '*.jpg', '*.jpeg'):\n",
        "    filenames.extend(glob.glob(os.path.join(data_dir, ext)))\n",
        "\n",
        "  # Load an average image and clusters(reference boxes of templates).\n",
        "  with open(weight_file_path, \"rb\") as f:\n",
        "    _, mat_params_dict = pickle.load(f)\n",
        "\n",
        "  average_image = model.get_data_by_key(\"average_image\")\n",
        "  clusters = model.get_data_by_key(\"clusters\")\n",
        "  clusters_h = clusters[:, 3] - clusters[:, 1] + 1\n",
        "  clusters_w = clusters[:, 2] - clusters[:, 0] + 1\n",
        "  normal_idx = np.where(clusters[:, 4] == 1)\n",
        "\n",
        "  # main\n",
        "  with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "\n",
        "    for filename in filenames:\n",
        "      fname = filename.split(os.sep)[-1]\n",
        "      raw_img = cv2.imread(filename)\n",
        "      raw_img = cv2.cvtColor(raw_img, cv2.COLOR_BGR2RGB)\n",
        "      raw_img_f = raw_img.astype(np.float32)\n",
        "\n",
        "      def _calc_scales():\n",
        "        raw_h, raw_w = raw_img.shape[0], raw_img.shape[1]\n",
        "        min_scale = min(np.floor(np.log2(np.max(clusters_w[normal_idx] / raw_w))),\n",
        "                        np.floor(np.log2(np.max(clusters_h[normal_idx] / raw_h))))\n",
        "        max_scale = min(1.0, -np.log2(max(raw_h, raw_w) / MAX_INPUT_DIM))\n",
        "        scales_down = np.arange(min_scale, 0, 1.)\n",
        "        scales_up = np.arange(0.5, max_scale, 0.5)\n",
        "        scales_pow = np.hstack((scales_down, scales_up))\n",
        "        scales = np.power(2.0, scales_pow)\n",
        "        return scales\n",
        "\n",
        "      scales = _calc_scales()\n",
        "      start = time.time()\n",
        "\n",
        "      # initialize output\n",
        "      bboxes = np.empty(shape=(0, 5))\n",
        "\n",
        "      # process input at different scales\n",
        "      for s in scales:\n",
        "        print(\"Processing {} at scale {:.4f}\".format(fname, s))\n",
        "        img = cv2.resize(raw_img_f, (0, 0), fx=s, fy=s, interpolation=cv2.INTER_LINEAR)\n",
        "        img = img - average_image\n",
        "        img = img[np.newaxis, :]\n",
        "\n",
        "        # we don't run every template on every scale ids of templates to ignore\n",
        "        tids = list(range(4, 12)) + ([] if s <= 1.0 else list(range(18, 25)))\n",
        "        ignoredTids = list(set(range(0, clusters.shape[0])) - set(tids))\n",
        "\n",
        "        # run through the net\n",
        "        score_final_tf = sess.run(score_final, feed_dict={x: img})\n",
        "\n",
        "        # collect scores\n",
        "        score_cls_tf, score_reg_tf = score_final_tf[:, :, :, :25], score_final_tf[:, :, :, 25:125]\n",
        "        prob_cls_tf = expit(score_cls_tf)\n",
        "        prob_cls_tf[0, :, :, ignoredTids] = 0.0\n",
        "\n",
        "        def _calc_bounding_boxes():\n",
        "          # threshold for detection\n",
        "          _, fy, fx, fc = np.where(prob_cls_tf > prob_thresh)\n",
        "\n",
        "          # interpret heatmap into bounding boxes\n",
        "          cy = fy * 8 - 1\n",
        "          cx = fx * 8 - 1\n",
        "          ch = clusters[fc, 3] - clusters[fc, 1] + 1\n",
        "          cw = clusters[fc, 2] - clusters[fc, 0] + 1\n",
        "\n",
        "          # extract bounding box refinement\n",
        "          Nt = clusters.shape[0]\n",
        "          tx = score_reg_tf[0, :, :, 0:Nt]\n",
        "          ty = score_reg_tf[0, :, :, Nt:2*Nt]\n",
        "          tw = score_reg_tf[0, :, :, 2*Nt:3*Nt]\n",
        "          th = score_reg_tf[0, :, :, 3*Nt:4*Nt]\n",
        "\n",
        "          # refine bounding boxes\n",
        "          dcx = cw * tx[fy, fx, fc]\n",
        "          dcy = ch * ty[fy, fx, fc]\n",
        "          rcx = cx + dcx\n",
        "          rcy = cy + dcy\n",
        "          rcw = cw * np.exp(tw[fy, fx, fc])\n",
        "          rch = ch * np.exp(th[fy, fx, fc])\n",
        "\n",
        "          scores = score_cls_tf[0, fy, fx, fc]\n",
        "          tmp_bboxes = np.vstack((rcx - rcw / 2, rcy - rch / 2, rcx + rcw / 2, rcy + rch / 2))\n",
        "          tmp_bboxes = np.vstack((tmp_bboxes / s, scores))\n",
        "          tmp_bboxes = tmp_bboxes.transpose()\n",
        "          return tmp_bboxes\n",
        "\n",
        "        tmp_bboxes = _calc_bounding_boxes()\n",
        "        bboxes = np.vstack((bboxes, tmp_bboxes)) # <class 'tuple'>: (5265, 5)\n",
        "\n",
        "\n",
        "      print(\"time {:.2f} secs for {}\".format(time.time() - start, fname))\n",
        "\n",
        "      # non maximum suppression\n",
        "      # refind_idx = util.nms(bboxes, nms_thresh)\n",
        "      refind_idx = tf.image.non_max_suppression(tf.convert_to_tensor(bboxes[:, :4], dtype=tf.float32),\n",
        "                                                   tf.convert_to_tensor(bboxes[:, 4], dtype=tf.float32),\n",
        "                                                   max_output_size=bboxes.shape[0], iou_threshold=nms_thresh)\n",
        "      refind_idx = sess.run(refind_idx)\n",
        "      refined_bboxes = bboxes[refind_idx]\n",
        "      overlay_bounding_boxes(raw_img, refined_bboxes, lw)\n",
        "\n",
        "      if display:\n",
        "        # plt.axis('off')\n",
        "        plt.imshow(raw_img)\n",
        "        plt.show()\n",
        "\n",
        "      # save image with bounding boxes\n",
        "      raw_img = cv2.cvtColor(raw_img, cv2.COLOR_RGB2BGR)\n",
        "      cv2.imwrite(os.path.join(output_dir, fname), raw_img)\n",
        "\n",
        "def main():\n",
        "\n",
        "  argparse = ArgumentParser()\n",
        "  argparse.add_argument('--weight_file_path', type=str, help='Pretrained weight file.', default=\"./path/to/hr_res101.pkl\")\n",
        "  argparse.add_argument('--data_dir', type=str, help='Image data directory.', default=\"./path/to/input_image_directory\")\n",
        "  argparse.add_argument('--output_dir', type=str, help='Output directory for images with faces detected.', default=\"./path/to/output_directory\")\n",
        "  argparse.add_argument('--prob_thresh', type=float, help='The threshold of detection confidence(default: 0.5).', default=0.5)\n",
        "  argparse.add_argument('--nms_thresh', type=float, help='The overlap threshold of non maximum suppression(default: 0.1).', default=0.1)\n",
        "  argparse.add_argument('--line_width', type=int, help='Line width of bounding boxes(0: auto).', default=3)\n",
        "  argparse.add_argument('--display', type=bool, help='Display each image on window.', default=True)\n",
        "\n",
        "  args = argparse.parse_args()\n",
        "\n",
        "  # check arguments\n",
        "  assert os.path.exists(args.weight_file_path), \"weight file: \" + args.weight_file_path + \" not found.\"\n",
        "  assert os.path.exists(args.data_dir), \"data directory: \" + args.data_dir + \" not found.\"\n",
        "  assert os.path.exists(args.output_dir), \"output directory: \" + args.output_dir + \" not found.\"\n",
        "  assert args.line_width >= 0, \"line_width should be >= 0.\"\n",
        "\n",
        "  with tf.Graph().as_default():\n",
        "    evaluate(\n",
        "      weight_file_path=args.weight_file_path, data_dir=args.data_dir, output_dir=args.output_dir,\n",
        "      prob_thresh=args.prob_thresh, nms_thresh=args.nms_thresh,\n",
        "      lw=args.line_width, display=args.display)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  main()\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-de9348e0bdc1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtiny_face_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0margparse\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mArgumentParser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tiny_face_model'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l322FbtxMwqm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "9194275b-5048-4773-af2e-02f2d396665c"
      },
      "source": [
        "argparse = ArgumentParser()\n",
        "argparse.add_argument('--matlab_model_path', type=str, help='Matlab pretrained model.',\n",
        "                      default='/path/to/hr_res101.mat')\n",
        "argparse.add_argument('--weight_file_path', type=str, help='Weight file for Tensorflow.',\n",
        "                      default='/path/to/mat2tf.pkl')\n",
        "\n",
        "args = argparse.parse_args()\n",
        "\n",
        "# check arguments\n",
        "assert os.path.exists(args.matlab_model_path), \\\n",
        "    \"Matlab pretrained model: \" + args.matlab_model_path + \" not found.\"\n",
        "assert os.path.exists(os.path.dirname((args.weight_file_path))),\\\n",
        "    \"Directory for weight file for Tensorflow: \" + args.weight_file_path + \" not found.\"\n",
        "\n",
        "mat_params_dict = {}\n",
        "mat_blocks_dict = {}\n",
        "\n",
        "f = sio.loadmat(args.matlab_model_path)\n",
        "net = f['net']\n",
        "clusters = np.copy(net['meta'][0][0][0][0][6])\n",
        "average_image = np.copy(net['meta'][0][0][0][0][2][0][0][2])[:, 0]\n",
        "mat_params_dict[\"clusters\"] = clusters\n",
        "mat_params_dict[\"average_image\"] = average_image\n",
        "\n",
        "layers = net['layers'][0][0][0]\n",
        "mat_params = net['params'][0][0][0]\n",
        "for p in mat_params:\n",
        "    mat_params_dict[p[0][0]] = p[1]\n",
        "\n",
        "for k, layer in enumerate(layers):\n",
        "    type_string = ''\n",
        "    param_string = ''\n",
        "\n",
        "    layer_name, layer_type = layer[0][0], layer[1][0]\n",
        "    layer_inputs = []\n",
        "    layer_outputs = []\n",
        "    layer_params = []\n",
        "\n",
        "    layer_inputs_count = layer[2][0].shape[0]\n",
        "    for i in range(layer_inputs_count):\n",
        "        layer_inputs.append(layer[2][0][i][0])\n",
        "\n",
        "    layer_outputs_count = layer[3][0].shape[0]\n",
        "    for i in range(layer_outputs_count):\n",
        "        layer_outputs.append(layer[3][0][i][0])\n",
        "\n",
        "    if layer[4].shape[0] > 0:\n",
        "        layer_params_count = layer[4][0].shape[0]\n",
        "        for i in range(layer_params_count):\n",
        "            layer_params.append(layer[4][0][i][0])\n",
        "\n",
        "    mat_blocks_dict[layer_name + '_type'] = layer_type\n",
        "    mat_params_dict[layer_name + '_type'] = layer_type\n",
        "    if layer_type == u'dagnn.Conv':\n",
        "        nchw = layer[5][0][0][0][0]\n",
        "        has_bias = layer[5][0][0][1][0][0]\n",
        "        pad = layer[5][0][0][3][0]\n",
        "        stride = layer[5][0][0][4][0]\n",
        "        dilate = layer[5][0][0][5][0]\n",
        "        mat_blocks_dict[layer_name + '_nchw'] = nchw\n",
        "        mat_blocks_dict[layer_name + '_has_bias'] = has_bias\n",
        "        mat_blocks_dict[layer_name + '_pad'] = pad\n",
        "        mat_blocks_dict[layer_name + '_stride'] = stride\n",
        "        mat_blocks_dict[layer_name + '_dilate'] = dilate\n",
        "        if has_bias:\n",
        "            bias = mat_params_dict[layer_name + '_bias'][0] # (1, N) -> (N,)\n",
        "            mat_params_dict[layer_name + '_bias'] = bias\n",
        "    elif layer_type == u'dagnn.BatchNorm':\n",
        "        epsilon = layer[5][0][0][1][0][0]\n",
        "        gamma = mat_params_dict[layer_name + '_mult'][:, 0] # (N, 1) -> (N,)\n",
        "        beta = mat_params_dict[layer_name + '_bias'][:, 0] # (N, 1) -> (N,)\n",
        "        moments = mat_params_dict[layer_name + '_moments'] # (N, 2) -> (N,), (N,)\n",
        "        moving_mean = moments[:, 0]\n",
        "        moving_var = moments[:, 1] * moments[:, 1] - epsilon\n",
        "\n",
        "        mat_blocks_dict[layer_name + '_variance_epsilon'] = epsilon\n",
        "        mat_params_dict[layer_name + '_scale'] = gamma\n",
        "        mat_params_dict[layer_name + '_offset'] = beta\n",
        "        mat_params_dict[layer_name + '_mean'] = moving_mean\n",
        "        mat_params_dict[layer_name + '_variance'] = moving_var\n",
        "    elif layer_type == u'dagnn.ConvTranspose':\n",
        "        nchw = layer[5][0][0][0][0]\n",
        "        has_bias = layer[5][0][0][1][0][0]\n",
        "        upsample = layer[5][0][0][2][0]\n",
        "        crop = layer[5][0][0][3][0]\n",
        "        mat_blocks_dict[layer_name + '_nchw'] = nchw\n",
        "        mat_blocks_dict[layer_name + '_has_bias'] = has_bias\n",
        "        mat_blocks_dict[layer_name + '_upsample'] = upsample\n",
        "        mat_blocks_dict[layer_name + '_crop'] = crop\n",
        "        wmat = mat_params_dict[layer_name + 'f']\n",
        "        mat_params_dict[layer_name + '_filter'] = wmat\n",
        "    elif layer_type == u'dagnn.Pooling':\n",
        "        method = layer[5][0][0][0][0]\n",
        "        pool_size = layer[5][0][0][1][0]\n",
        "        pad = layer[5][0][0][3][0]\n",
        "        stride = layer[5][0][0][4][0]\n",
        "        mat_blocks_dict[layer_name + '_method'] = method\n",
        "        mat_blocks_dict[layer_name + '_pool_size'] = pool_size\n",
        "        mat_blocks_dict[layer_name + '_pad'] = pad\n",
        "        mat_blocks_dict[layer_name + '_stride'] = stride\n",
        "    elif layer_type == u'dagnn.ReLU':\n",
        "        pass\n",
        "    elif layer_type == u'dagnn.Sum':\n",
        "        pass\n",
        "    else:\n",
        "        pass\n",
        "\n",
        "with open(args.weight_file_path, 'wb') as f:\n",
        "    pickle.dump([mat_blocks_dict, mat_params_dict], f, pickle.HIGHEST_PROTOCOL)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "usage: ipykernel_launcher.py [-h] [--matlab_model_path MATLAB_MODEL_PATH]\n",
            "                             [--weight_file_path WEIGHT_FILE_PATH]\n",
            "ipykernel_launcher.py: error: unrecognized arguments: -f /root/.local/share/jupyter/runtime/kernel-60ff6b28-21aa-4049-aa72-7a8bbd38a3ed.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0wOO7lPNIWT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}