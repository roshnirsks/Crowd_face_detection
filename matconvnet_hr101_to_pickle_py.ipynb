{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "matconvnet_hr101_to_pickle.py",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8gdu17DMiEv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import numpy as np\n",
        "import scipy.io as sio\n",
        "import os\n",
        "import pickle\n",
        "from argparse import ArgumentParser"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l322FbtxMwqm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "9194275b-5048-4773-af2e-02f2d396665c"
      },
      "source": [
        "argparse = ArgumentParser()\n",
        "argparse.add_argument('--matlab_model_path', type=str, help='Matlab pretrained model.',\n",
        "                      default='/path/to/hr_res101.mat')\n",
        "argparse.add_argument('--weight_file_path', type=str, help='Weight file for Tensorflow.',\n",
        "                      default='/path/to/mat2tf.pkl')\n",
        "\n",
        "args = argparse.parse_args()\n",
        "\n",
        "# check arguments\n",
        "assert os.path.exists(args.matlab_model_path), \\\n",
        "    \"Matlab pretrained model: \" + args.matlab_model_path + \" not found.\"\n",
        "assert os.path.exists(os.path.dirname((args.weight_file_path))),\\\n",
        "    \"Directory for weight file for Tensorflow: \" + args.weight_file_path + \" not found.\"\n",
        "\n",
        "mat_params_dict = {}\n",
        "mat_blocks_dict = {}\n",
        "\n",
        "f = sio.loadmat(args.matlab_model_path)\n",
        "net = f['net']\n",
        "clusters = np.copy(net['meta'][0][0][0][0][6])\n",
        "average_image = np.copy(net['meta'][0][0][0][0][2][0][0][2])[:, 0]\n",
        "mat_params_dict[\"clusters\"] = clusters\n",
        "mat_params_dict[\"average_image\"] = average_image\n",
        "\n",
        "layers = net['layers'][0][0][0]\n",
        "mat_params = net['params'][0][0][0]\n",
        "for p in mat_params:\n",
        "    mat_params_dict[p[0][0]] = p[1]\n",
        "\n",
        "for k, layer in enumerate(layers):\n",
        "    type_string = ''\n",
        "    param_string = ''\n",
        "\n",
        "    layer_name, layer_type = layer[0][0], layer[1][0]\n",
        "    layer_inputs = []\n",
        "    layer_outputs = []\n",
        "    layer_params = []\n",
        "\n",
        "    layer_inputs_count = layer[2][0].shape[0]\n",
        "    for i in range(layer_inputs_count):\n",
        "        layer_inputs.append(layer[2][0][i][0])\n",
        "\n",
        "    layer_outputs_count = layer[3][0].shape[0]\n",
        "    for i in range(layer_outputs_count):\n",
        "        layer_outputs.append(layer[3][0][i][0])\n",
        "\n",
        "    if layer[4].shape[0] > 0:\n",
        "        layer_params_count = layer[4][0].shape[0]\n",
        "        for i in range(layer_params_count):\n",
        "            layer_params.append(layer[4][0][i][0])\n",
        "\n",
        "    mat_blocks_dict[layer_name + '_type'] = layer_type\n",
        "    mat_params_dict[layer_name + '_type'] = layer_type\n",
        "    if layer_type == u'dagnn.Conv':\n",
        "        nchw = layer[5][0][0][0][0]\n",
        "        has_bias = layer[5][0][0][1][0][0]\n",
        "        pad = layer[5][0][0][3][0]\n",
        "        stride = layer[5][0][0][4][0]\n",
        "        dilate = layer[5][0][0][5][0]\n",
        "        mat_blocks_dict[layer_name + '_nchw'] = nchw\n",
        "        mat_blocks_dict[layer_name + '_has_bias'] = has_bias\n",
        "        mat_blocks_dict[layer_name + '_pad'] = pad\n",
        "        mat_blocks_dict[layer_name + '_stride'] = stride\n",
        "        mat_blocks_dict[layer_name + '_dilate'] = dilate\n",
        "        if has_bias:\n",
        "            bias = mat_params_dict[layer_name + '_bias'][0] # (1, N) -> (N,)\n",
        "            mat_params_dict[layer_name + '_bias'] = bias\n",
        "    elif layer_type == u'dagnn.BatchNorm':\n",
        "        epsilon = layer[5][0][0][1][0][0]\n",
        "        gamma = mat_params_dict[layer_name + '_mult'][:, 0] # (N, 1) -> (N,)\n",
        "        beta = mat_params_dict[layer_name + '_bias'][:, 0] # (N, 1) -> (N,)\n",
        "        moments = mat_params_dict[layer_name + '_moments'] # (N, 2) -> (N,), (N,)\n",
        "        moving_mean = moments[:, 0]\n",
        "        moving_var = moments[:, 1] * moments[:, 1] - epsilon\n",
        "\n",
        "        mat_blocks_dict[layer_name + '_variance_epsilon'] = epsilon\n",
        "        mat_params_dict[layer_name + '_scale'] = gamma\n",
        "        mat_params_dict[layer_name + '_offset'] = beta\n",
        "        mat_params_dict[layer_name + '_mean'] = moving_mean\n",
        "        mat_params_dict[layer_name + '_variance'] = moving_var\n",
        "    elif layer_type == u'dagnn.ConvTranspose':\n",
        "        nchw = layer[5][0][0][0][0]\n",
        "        has_bias = layer[5][0][0][1][0][0]\n",
        "        upsample = layer[5][0][0][2][0]\n",
        "        crop = layer[5][0][0][3][0]\n",
        "        mat_blocks_dict[layer_name + '_nchw'] = nchw\n",
        "        mat_blocks_dict[layer_name + '_has_bias'] = has_bias\n",
        "        mat_blocks_dict[layer_name + '_upsample'] = upsample\n",
        "        mat_blocks_dict[layer_name + '_crop'] = crop\n",
        "        wmat = mat_params_dict[layer_name + 'f']\n",
        "        mat_params_dict[layer_name + '_filter'] = wmat\n",
        "    elif layer_type == u'dagnn.Pooling':\n",
        "        method = layer[5][0][0][0][0]\n",
        "        pool_size = layer[5][0][0][1][0]\n",
        "        pad = layer[5][0][0][3][0]\n",
        "        stride = layer[5][0][0][4][0]\n",
        "        mat_blocks_dict[layer_name + '_method'] = method\n",
        "        mat_blocks_dict[layer_name + '_pool_size'] = pool_size\n",
        "        mat_blocks_dict[layer_name + '_pad'] = pad\n",
        "        mat_blocks_dict[layer_name + '_stride'] = stride\n",
        "    elif layer_type == u'dagnn.ReLU':\n",
        "        pass\n",
        "    elif layer_type == u'dagnn.Sum':\n",
        "        pass\n",
        "    else:\n",
        "        pass\n",
        "\n",
        "with open(args.weight_file_path, 'wb') as f:\n",
        "    pickle.dump([mat_blocks_dict, mat_params_dict], f, pickle.HIGHEST_PROTOCOL)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "usage: ipykernel_launcher.py [-h] [--matlab_model_path MATLAB_MODEL_PATH]\n",
            "                             [--weight_file_path WEIGHT_FILE_PATH]\n",
            "ipykernel_launcher.py: error: unrecognized arguments: -f /root/.local/share/jupyter/runtime/kernel-60ff6b28-21aa-4049-aa72-7a8bbd38a3ed.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0wOO7lPNIWT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}